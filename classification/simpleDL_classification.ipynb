{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple image classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 예제는 간단한 CNN을 이용해서 image를 분류해 보는 과정입니다. \n",
    "Tensorflow 같은 경우 tutorial이 잘 마련되어 있고, mnist data (숫자 0부터 9까지의 손글씨 그림)를 구분하는 예제 같은 경우 대부분 별 어려움 없이 따라해 보실 수 있을 것입니다. \n",
    "\n",
    "그러나, 막상 본인의 데이터를 가지고 비슷한 것을 해보려고 할 때 프로그래밍이 익숙하지 않으신 분들은 대부분 여기에서 어려움을 겪게 되는 것 같습니다. \n",
    "\n",
    "그래서 tensorflow 홈페이지에 나와 있는 deep learning을 이용한 MNIST data (28X28 images)를 구분하는 예제를 수정하여 제가 가지고 있는 256x256 images에 적용하는 과정을 정리해 보았습니다.\n",
    "\n",
    "Tensorflow Deep MNIST example\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "본 예제에 필요한 외부 라이브러리는 skimage, numpy입니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 두 줄은 MNIST data를 웹으로부터 다운로드하고 불러오는 과정입니다. \n",
    "실제 여기서는 연산에 사용하지 않을 것이지만, \n",
    "어떠한 형태로 본인의 데이터를 준비해야 되는 지 참고할 수 있도록 넣어 보았습니다.\n",
    "mnist.을 입력하고 tab을 누르면 mnist가 가지고 있는 하위 구조가 표시됩니다. \n",
    "mnist.train.images.shape를 해보면 train에 사용된 image data가 55000개가 784개의 성분을 가지는 vector의 형태로 저장된 것을 확인할 수 있습니다. 이는 28x28의 2D image를 1D로 배열된 데이터이기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labe같은 경우는 10개의 성분을 가지는 vector로 되어 있음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 어떻게 되어 있는 지 하나를 가져와서 보면\n",
    "나머지는 다 0이고 9번째 성분만 1인 벡터임을 알 수 있습니다. \n",
    "아마도 8이라는 숫자를 이런 규칙으로 표현했을 것입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmplabel = mnist.train.labels[1111]\n",
    "tmplabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국 이 예제에서의 label은 만약 class가 4개라면 각각 아래처럼 준비하면 되겠다는 것을 알 수 있습니다.\n",
    "[1, 0, 0, 0]\n",
    "[0, 1, 0, 0]\n",
    "[0, 0, 1, 0]\n",
    "[0, 0, 0, 1]\n",
    "\n",
    "아래부터가 tensorflow를 이용한 저희의 예제의 시작입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제가 준비한 데이터는 각각 256장의 사각형과 삼각형 그림입니다. \n",
    "그림은 png로 저장되어 있고, 256x256 사이즈로 저장되어 있습니다. \n",
    "(별로 좋은 데이터는 아닙니다. 256개의 그림이 사실상 같은 삼각형/사각형입니다. 단지 코드가 돌아가는 것을 보여주기 위한 그림입니다.)\n",
    "mydata라는 폴더 안에 사각형은 0이라는 폴더, 삼각형은 1이라는 폴더에 넣었습니다.\n",
    "본인의 그림으로 테스트를 할 경우 class별로 폴더를 만들어서 정리해 넣으면 됩니다.\n",
    "예제에 포함되어 있는 mydata 폴더를 참고해주세요.\n",
    "\n",
    "단, 이 예제에서는 그림은 모두 같은 사이즈의 흑백그림이어야 합니다.\n",
    "256x256이 아닌 사이즈를 테스트 하려면 코드의 일부를 수정해야 합니다.\n",
    "\n",
    "아래의 코드는 mydata라는 폴더 안에 있는 png파일들의 list를 준비하면서 각각 속한 하위폴더에 따라 label을 입력하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pathimg = \"./mydata\"\n",
    "imgfiles = []\n",
    "imgtype = []\n",
    "dn=0\n",
    "n=0\n",
    "for dirName, subdirList, fileList in os.walk(pathimg):\n",
    "    print(dirName, dn)\n",
    "    for filename in fileList:\n",
    "        if \".png\" in filename.lower():\n",
    "            imgfiles.append(os.path.join(dirName,filename))\n",
    "            imgtype.append(dn)\n",
    "    dn=dn+1\n",
    "Nclass = dn-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 img, label을 각각 image data, label을 넣기 위해 준비합니다. \n",
    "label.shape를 통해 전체 image의 개수와 class의 개수가 제대로 되었는 지 확인합니다.\n",
    "image size가 256x256이 아니면 256,256을 수정하여야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.zeros((len(imgfiles),256,256), dtype=float)\n",
    "label = np.zeros((len(imgfiles), Nclass), dtype=float)\n",
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 이미지를 메모리로 불러어고 label vector를 준비하는 과정입니다.\n",
    "저희 예제처럼 작은 데이터를 가지고 학습을 할 때는 이처럼 memory에 모든 데이터를 불러와서 작업을 할 수 있지만,\n",
    "다루는 데이터 및 네트워크의 규모가 RAM의 크기로 감당이 되지 않는 큰 경우에는 이런 식으로 작업할 수는 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "for n in range(len(imgfiles)):\n",
    "    img[n]=imread(imgfiles[n])\n",
    "    ln = imgtype[n]-1\n",
    "    label[n,ln] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 작업은 random하게 90% 정도의 index를 train으로 할당하고, 나머지를 valid로 할당하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(len(img),round(len(img)*0.9), replace = False)\n",
    "valid_indices = np.array(list(set(range(len(img))) - set(train_indices)))\n",
    "\n",
    "img_train = img[train_indices]\n",
    "img_valid = img[valid_indices]\n",
    "label_train = label[train_indices]\n",
    "label_valid = label[valid_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 network는 tensorflow에서 작성한 것으로 deepnn이라는 함수를 정의해서 CNN의 구조를 만들었습니다.\n",
    "원래의 예제에서 이미지 사이즈인 28x28에 해당하는 부분들을 256x256에 쓸 수 있도록 숫자들을 변경하였습니다.\n",
    "만약 image size를 변경할 경우, 아래 세 줄을 찾아서 해당하는 숫자로 바꾸어 주어야 합니다. 2,3번째 행의 64는 256을 4로 나눈 값입니다. \n",
    "        x_image = tf.reshape(x, [-1, 256, 256, 1]) # 28, 28 -> 256, 256 image size가 들어가면 됩니다.\n",
    "        W_fc1 = weight_variable([64 * 64 * 64, 1024]) # image size를 4로 나눈 값을 K라고 하면  k*k*64를 넣으면 됩니다. 다음 행도.\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 64 * 64 * 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "\n",
    "  # Reshape to use within a convolutional neural net.\n",
    "  # Last dimension is for \"features\" - there is only one here, since images are\n",
    "  # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "  \n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 256, 256, 1]) # 28, 28 -> 256, 256\n",
    "        \n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "  # Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image ->256x256 image\n",
    "  # is down to 7x7x64 feature maps -- maps this to 1024 features. -> 64x64x64 feature maps\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([64 * 64 * 64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 64*64*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "  # features.\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "  # Map the 1024 features to 10 classes, one for each digit -> N classes\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([1024, Nclass])\n",
    "        b_fc2 = bias_variable([Nclass])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "  \n",
    "    return y_conv, keep_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 deepnn이라는 메인 network함수에서 자주 사용되는 함수들을 정의해 놓은 것입니다.\n",
    "def는 함수를 정의한 것으로 실제 실행은 저 함수가 호출되었을 때 일어납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)  \n",
    "    return tf.Variable(initial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 위한 아래와 같은 몇 가지 준비가 더 필요합니다.\n",
    "image size를 바꿀 경우 256, 256을 본인의 사이즈로 바꾸면 됩니다. \n",
    "\n",
    "여기서 중요한 파라미터가 하나 있는데 AdamOptimizer에서 사용하는 1e-3 입니다.\n",
    "0.001을 표현한 것으로 저 숫자가 작을 수록 학습하는 정도가 바뀝니다. 만약 학습 결과의 변동이 너무 심하거나 하면, \n",
    "저 숫자를 1e-4, 1e-5 등으로 줄여줄 필요가 있습니다. \n",
    "\n",
    "학습의 결과가 너무 변하지 않는 것 같으면 1e-2로 올려서 테스트 해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, shape = [None, 256, 256])   # 256, 256 -> image size\n",
    "\n",
    "  # Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, shape =[None, Nclass])\n",
    "\n",
    "  # Build the graph for the deep net\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y_conv)\n",
    "  \n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "  \n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 학습과 관련된 연산이 일어나는 것은 아래의 단락을 실행하였을 때입니다.\n",
    "for i in range(128)의 128은 128번 반복 학습을 하라는 것이고\n",
    "batch_indices는 전체 데이터 중 한 번 학습을 할 때 랜덤으로 몇 개의 데이터를 추출해서 쓰겠냐는 것인데\n",
    "메모리사이즈와 데이터크기를 고려해서 정해주어야 합니다. 여기서는 16으로 하였습니다.\n",
    "\n",
    "작업이 끝나고 마지막으로 valid set에 대한 accuracy를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(32):\n",
    "        batch_indices = np.random.choice(len(img_train),16, replace=False)\n",
    "        img_batch = img_train[batch_indices]\n",
    "        label_batch = label_train[batch_indices]\n",
    "        if i % 8 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: img_batch, y_: label_batch, keep_prob: 1.0})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy)) \n",
    "        train_step.run(feed_dict={x: img_batch, y_: label_batch, keep_prob: 0.5})\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={   \n",
    "        x: img_valid, y_: label_valid, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
